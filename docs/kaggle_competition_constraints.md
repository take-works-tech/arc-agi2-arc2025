# Kaggleコンペ制限への対応

> **目的**: Kaggleコンペの制限（実行時間、メモリ、GPU、ファイルサイズなど）を考慮した実装設計

## 📋 目次

1. [Kaggleコンペの一般的な制限](#1-kaggleコンペの一般的な制限)
2. [現在の実装の制限事項](#2-現在の実装の制限事項)
3. [改善提案の制限事項](#3-改善提案の制限事項)
4. [対策と最適化](#4-対策と最適化)

---

## 1. Kaggleコンペの一般的な制限

### 1.1 実行時間制限

- **推論時間**: 通常、1タスクあたり数秒〜数十秒
- **全体の実行時間**: 100タスクで数分〜数十分
- **タイムアウト**: 長時間実行される処理は中断される可能性

### 1.2 メモリ制限

- **CPUメモリ**: 通常、8GB〜16GB
- **GPUメモリ**: 通常、16GB〜32GB（T4、V100など）
- **メモリリーク**: 長時間実行でメモリが増加するとOOMエラー

### 1.3 GPU制限

- **GPU使用時間**: 推論時間に応じて制限
- **GPUメモリ**: 複数のモデルを同時にロードすると制限に達する可能性
- **GPUの有無**: CPUのみの環境も考慮が必要

### 1.4 ファイルサイズ制限

- **提出ファイル**: 通常、数百MB〜数GB
- **モデルファイル**: 複数のモデルを保存するとサイズが大きくなる
- **依存関係**: ライブラリのサイズも考慮が必要

### 1.5 依存関係の制限

- **インターネットアクセス**: 通常、推論時はオフライン
- **外部API**: 使用不可
- **モデルのダウンロード**: 事前にダウンロードが必要

---

## 2. 現在の実装の制限事項

### 2.1 メモリ使用量

**問題点**:
- 複数の深層学習モデルを同時にロード
  - `ProgramSynthesisModel`（グリッド→プログラム）
  - `ObjectBasedProgramSynthesisModel`（オブジェクト→プログラム）
  - `GridToGridModel`（グリッド→グリッド）
  - `ProgramScorer`（MLP）
- オブジェクトマッチングで大量の部分プログラムを生成（最大930個、重複排除後200-300個）
- 各部分プログラム × 各訓練ペアの組み合わせで候補生成

**推定メモリ使用量**:
- モデルロード: 約1-2GB（GPU）
- オブジェクトマッチング: 約500MB-1GB（CPU）
- 候補生成: 約500MB-1GB（GPU）
- **合計: 約2-4GB（GPU）+ 1-2GB（CPU）**

### 2.2 実行時間

**問題点**:
- オブジェクトマッチング: 数秒〜数十秒（カテゴリ分類が重い）
- 候補生成: 各部分プログラム × 各訓練ペア × 複数の候補生成方法
- 一貫性チェック: すべての候補プログラムを実行

**推定実行時間**（1タスクあたり）:
- オブジェクトマッチング: 5-10秒
- 候補生成: 10-30秒（部分プログラム数 × 訓練ペア数 × 候補生成方法数）
- 一貫性チェック: 5-15秒
- **合計: 20-55秒/タスク**

### 2.3 ファイルサイズ

**問題点**:
- 複数のモデルファイル
  - `ProgramSynthesisModel`: 約100-500MB
  - `ObjectBasedProgramSynthesisModel`: 約100-500MB
  - `GridToGridModel`: 約100-500MB
  - `ProgramScorer`: 約1-10MB
- **合計: 約300-1500MB**

---

## 3. 改善提案の制限事項

### 3.1 追加されるモデル

**新規追加されるモデル**:
- **NGPS（Neural Guided Program Search）**: 約50-200MB
- **DSL Selector**: 約10-50MB
- **Object Graph + GNN Encoder**: 約100-300MB
- **Relation Classifier**: 約10-50MB
- **Neural Mask Generator**: 約50-200MB
- **Meta-Reasoner（Strategy Classifier + Module Router）**: 約50-200MB

**推定追加メモリ使用量**: 約270-1000MB

**合計メモリ使用量**: 約2.3-5GB（GPU）+ 1-2GB（CPU）

### 3.2 実行時間への影響

**改善による時間短縮**:
- **NGPS**: 探索空間を1000倍縮小 → 実行時間を大幅に削減
- **プログラム検証レイヤー**: 無効な候補を事前にフィルタリング → 一貫性チェック時間を削減

**改善による時間増加**:
- **Object Graph + GNN**: グラフ構築とGNNエンコーディング → 数秒追加
- **Relation Classifier**: 関係性分類 → 数秒追加
- **Meta-Reasoner**: 戦略分類とDSL Selector → 数秒追加

**推定実行時間**（1タスクあたり、改善後）:
- オブジェクトマッチング: 5-10秒（対応関係分析無効化で短縮）
- Object Graph + GNN: 2-5秒（新規追加）
- 候補生成（NGPS使用）: 5-15秒（NGPSで短縮）
- プログラム検証: 1-3秒（新規追加）
- 一貫性チェック: 3-10秒（検証レイヤーで短縮）
- **合計: 16-43秒/タスク**（改善前より短縮）

### 3.3 ファイルサイズへの影響

**追加されるモデルファイル**:
- NGPS: 約50-200MB
- DSL Selector: 約10-50MB
- Object Graph + GNN Encoder: 約100-300MB
- Relation Classifier: 約10-50MB
- Neural Mask Generator: 約50-200MB
- Meta-Reasoner: 約50-200MB

**推定追加ファイルサイズ**: 約270-1000MB

**合計ファイルサイズ**: 約570-2500MB

---

## 4. 対策と最適化

### 4.1 メモリ使用量の最適化

#### 4.1.1 モデルの遅延ロード

**実装**:
- 必要な時だけモデルをロード
- 使用後は即座にアンロード
- GPUメモリのクリアを徹底

**効果**: メモリ使用量を50-70%削減

#### 4.1.2 モデルの共有

**実装**:
- 共通のエンコーダーを複数のモデルで共有
- 軽量なモデルアーキテクチャを使用

**効果**: メモリ使用量を30-50%削減

#### 4.1.3 バッチ処理の最適化

**実装**:
- 候補生成をバッチ処理
- メモリ制限に達したら処理を中断

**効果**: メモリ使用量の制御

#### 4.1.4 部分プログラム数の制限

**実装**:
- 部分プログラム数を制限（例: 最大50個）
- 優先度の高い部分プログラムのみを使用

**効果**: メモリ使用量と実行時間を削減

### 4.2 実行時間の最適化

#### 4.2.1 並列処理の最適化

**実装**:
- 並列処理のワーカー数を制限（例: 最大2-4ワーカー）
- CPUのみの環境では並列処理を無効化

**効果**: 実行時間の安定化

#### 4.2.2 早期終了

**実装**:
- 一貫性スコアが1.0の候補が見つかったら早期終了
- タイムアウト設定を追加

**効果**: 実行時間の削減

#### 4.2.3 キャッシュの活用

**実装**:
- オブジェクト抽出結果をキャッシュ
- プログラム実行結果をキャッシュ

**効果**: 実行時間の削減

### 4.3 ファイルサイズの最適化

#### 4.3.1 モデルの量子化

**実装**:
- モデルをINT8に量子化
- モデルのプルーニング

**効果**: ファイルサイズを50-75%削減

#### 4.3.2 モデルの統合

**実装**:
- 複数のモデルを1つのモデルに統合
- マルチタスク学習

**効果**: ファイルサイズを30-50%削減

#### 4.3.3 モデルの選択的ロード

**実装**:
- 必要なモデルのみをロード
- 設定でモデルを有効/無効化

**効果**: ファイルサイズの削減（使用しないモデルは含めない）

### 4.4 Kaggleコンペ向けの推奨設定

#### 4.4.1 メモリ制限対応

```python
# 推奨設定
config = SynthesisConfig(
    max_candidates_per_pair=5,  # 10 → 5に削減
    enable_parallel_processing=False,  # 並列処理を無効化（メモリ節約）
    memory_limit_mb=2048.0,  # メモリ制限を設定
    enable_memory_monitoring=True,  # メモリ監視を有効化
)

candidate_config = CandidateConfig(
    num_neural_candidates_with_partial=10,  # 20 → 10に削減
    num_neural_candidates_without_partial=10,  # 20 → 10に削減
    num_neural_object_candidates_with_partial=10,  # 20 → 10に削減
    num_neural_object_candidates_without_partial=10,  # 20 → 10に削減
    num_grid_to_grid_candidates=10,  # 20 → 10に削減
)

object_matching_config = ObjectMatchingConfig(
    num_category_patterns_4=100,  # 463 → 100に削減
    num_category_patterns_8=100,  # 463 → 100に削減
    enable_correspondence_detection=False,  # 対応関係分析を無効化
)
```

#### 4.4.2 実行時間制限対応

```python
# 推奨設定
config = SynthesisConfig(
    timeout_seconds=20.0,  # 30 → 20に削減
    max_synthesis_attempts=50,  # 100 → 50に削減
    enable_early_stopping=True,  # 早期終了を有効化
)
```

#### 4.4.3 GPU制限対応

```python
# 推奨設定
# モデルの遅延ロード
# 使用後は即座にアンロード
# GPUメモリのクリアを徹底

import torch

def clear_gpu_memory():
    """GPUメモリをクリア"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
```

---

## 5. 制限事項のまとめ

### 5.1 現在の実装の制限事項

| 項目 | 現在の値 | Kaggle制限 | 問題 |
|------|---------|-----------|------|
| **メモリ使用量（GPU）** | 2-4GB | 16-32GB | ✅ 問題なし |
| **メモリ使用量（CPU）** | 1-2GB | 8-16GB | ✅ 問題なし |
| **実行時間（1タスク）** | 20-55秒 | 数秒〜数十秒 | ⚠️ やや長い |
| **ファイルサイズ** | 300-1500MB | 数百MB〜数GB | ✅ 問題なし |

### 5.2 改善提案の制限事項

| 項目 | 改善後の値 | Kaggle制限 | 問題 |
|------|-----------|-----------|------|
| **メモリ使用量（GPU）** | 2.3-5GB | 16-32GB | ✅ 問題なし |
| **メモリ使用量（CPU）** | 1-2GB | 8-16GB | ✅ 問題なし |
| **実行時間（1タスク）** | 16-43秒 | 数秒〜数十秒 | ⚠️ やや長い（改善） |
| **ファイルサイズ** | 570-2500MB | 数百MB〜数GB | ⚠️ やや大きい |

### 5.3 推奨される最適化

1. **メモリ使用量の最適化**
   - モデルの遅延ロード
   - 部分プログラム数の制限
   - 並列処理の無効化

2. **実行時間の最適化**
   - 早期終了の実装
   - キャッシュの活用
   - 候補生成数の削減

3. **ファイルサイズの最適化**
   - モデルの量子化
   - モデルの統合
   - 選択的ロード

---

## 6. 実装時の注意事項

### 6.1 メモリ管理

- モデルのロード/アンロードを適切に管理
- GPUメモリのクリアを徹底
- メモリ監視を有効化

### 6.2 実行時間管理

- タイムアウト設定を追加
- 早期終了を実装
- 実行時間のログを記録

### 6.3 エラーハンドリング

- メモリ不足時のフォールバック
- タイムアウト時の処理
- 部分的な結果の返却

---

## 7. 追加提案の評価（Claudeの提案）

### 7.1 採用すべき提案

#### ✅ Cross-Attention between Input/Outputの強化

**評価**: 採用推奨（Tier 2）

**理由**:
- 実装が容易（Transformerの標準的な機能）
- 効果が高い（変換パターンを明示的に学習）
- 計算コストがそれほど高くない
- メモリ使用量への影響も小さい

**Kaggle制限への影響**:
- メモリ使用量: +50-100MB（軽微）
- 実行時間: +0.5-1秒（軽微）
- ファイルサイズ: +10-20MB（軽微）

#### ✅ Symmetry-Aware Augmentation

**評価**: 採用推奨（Tier 3）

**理由**:
- Object Canonicalizationと相補的
- 実装も比較的容易
- 効果も期待できる
- 学習時のみの処理（推論時には影響なし）

**Kaggle制限への影響**:
- メモリ使用量: 影響なし（学習時のみ）
- 実行時間: 影響なし（学習時のみ）
- ファイルサイズ: 影響なし

### 7.2 検討が必要な提案

#### ⚠️ Diffusion-based Program Synthesis

**評価**: 現時点では導入を見送り（将来的に検討）

**理由**:
- 最新研究では効果があるとされている
- ただし、計算コストが高い
- Kaggleの実行時間制限を考慮すると、追加の計算負荷が問題になる可能性
- 実装の複雑さも高い

**Kaggle制限への影響**:
- メモリ使用量: +500MB-1GB（大きい）
- 実行時間: +10-30秒（大きい）
- ファイルサイズ: +200-500MB（大きい）

**判断**: 現時点では導入を見送り。将来的に、実行時間制限に余裕がある場合や、他の最適化が完了した後に検討。

#### ⚠️ Program Sketch + Neural Completion

**評価**: 既存の部分プログラム生成を改善する方向で検討

**理由**:
- 2段階アプローチは有効
- ただし、既存の部分プログラム生成と重複する可能性
- 実装の複雑さは中程度

**Kaggle制限への影響**:
- メモリ使用量: +100-200MB（中程度）
- 実行時間: +2-5秒（中程度）
- ファイルサイズ: +50-100MB（中程度）

**判断**: 既存の部分プログラム生成を改善する方向で検討。新しいモジュールとして追加するのではなく、既存の部分プログラム生成を2段階アプローチに変更することを検討。

### 7.3 導入を見送る提案

#### ❌ Few-shot In-Context Learning

**評価**: 導入を見送り

**理由**:
- 大規模言語モデルが必要
- Kaggleではモデルサイズの制限がある
- 実装の複雑さが高い
- インターネットアクセスが必要（推論時はオフライン）

**Kaggle制限への影響**:
- メモリ使用量: +2-5GB（非常に大きい）
- 実行時間: +20-60秒（非常に大きい）
- ファイルサイズ: +1-3GB（非常に大きい）

#### ❌ Curriculum Learning

**評価**: 推論パイプラインのドキュメントには含めない

**理由**:
- これは学習段階での改善
- 推論時には影響しない
- 推論パイプラインのドキュメントには含めない

#### ✅ Program Verifier

**評価**: 既に「プログラム検証レイヤー」として提案済み

**理由**:
- 既に「プログラム検証レイヤーの強化」としてTier 2に含まれている
- 重複しているため、追加不要

---

## 8. 結論

**現在の実装と改善提案は、Kaggleコンペの制限内で動作可能**です。

**ただし、以下の最適化を推奨**:
1. メモリ使用量の最適化（モデルの遅延ロード、部分プログラム数の制限）
2. 実行時間の最適化（早期終了、キャッシュの活用）
3. ファイルサイズの最適化（モデルの量子化、選択的ロード）

**追加提案の採用判断**:
- ✅ **Cross-Attention between Input/Outputの強化**（Tier 2）: 採用推奨
- ✅ **Symmetry-Aware Augmentation**（Tier 3）: 採用推奨
- ⚠️ **Diffusion-based Program Synthesis**: 現時点では導入を見送り（将来的に検討）
- ⚠️ **Program Sketch + Neural Completion**: 既存の部分プログラム生成を改善する方向で検討
- ❌ **Few-shot In-Context Learning**: 導入を見送り
- ❌ **Curriculum Learning**: 推論パイプラインのドキュメントには含めない
- ✅ **Program Verifier**: 既に提案済み（追加不要）

これらの最適化により、Kaggleコンペの制限内で安定して動作し、精度も向上します。
